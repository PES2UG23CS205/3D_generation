# -*- coding: utf-8 -*-
"""3D_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EegVQuOJ5YndpAdtiiDSdMgs4OMDwV0m
"""

# ==============================================================================
# Step 1: Install All Necessary Libraries
# ==============================================================================
# We do this first in a separate cell in Colab.
!pip install -q diffusers transformers accelerate bitsandbytes torch torchvision
!pip install -q fastapi uvicorn pyngrok "uvicorn[standard]" nest_asyncio
!pip install -q pyvista ipythreejs imageio imageio[ffmpeg] trimesh

!pip install ipywidgets
!pip install pythreejs

!pip install git+https://github.com/openai/shap-e.git

!pip install pyvista

import torch
import os
import uuid
import time
from diffusers import ShapEImg2ImgPipeline, ShapEPipeline
from diffusers.utils import export_to_ply

import fastapi
from fastapi import FastAPI, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
import nest_asyncio
from pyngrok import ngrok
import imageio
import trimesh
import pyvista as pv
import traceback

# Create a directory to store our generated assets
if not os.path.exists("generated_assets"):
    os.makedirs("generated_assets")

print("‚úÖ Environment setup complete.")

jobs = {}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‚úÖ Using device: {device}")

print("‚è≥ Loading Shap-E model... (This might take a minute)")
pipe = ShapEPipeline.from_pretrained("openai/shap-e", torch_dtype=torch.float16).to(device)
print("‚úÖ Shap-E model loaded successfully!")

MODEL_VERSION = "openai/shap-e"
UPTIME = time.time()

def generate_3d_asset(job_id: str, prompt: str):
    try:
        jobs[job_id]["status"] = "processing"
        print(f"üöÄ Starting job {job_id} for prompt: '{prompt}'")

        output = pipe(
            prompt, guidance_scale=15.0, num_inference_steps=64, frame_size=256, output_type="mesh",
        ).images[0]

        ply_filename = f"generated_assets/{job_id}.ply"
        export_to_ply(output, ply_filename)
        print(f"‚úÖ Saved PLY file: {ply_filename}")

        glb_filename = f"generated_assets/{job_id}.glb"
        trimesh.load(ply_filename).export(glb_filename)
        print(f"‚úÖ Converted to GLB file: {glb_filename}")

        print("‚è≥ Generating GIF preview using PyVista...")
        gif_filename = f"generated_assets/{job_id}.gif"

        # This is the correct way: specify off_screen directly in the plotter
        plotter = pv.Plotter(off_screen=True, window_size=[400, 400])
        mesh = pv.read(glb_filename)
        plotter.add_mesh(mesh, color="lightblue", smooth_shading=True)
        plotter.camera_position = 'xy'
        plotter.camera.elevation = -10

        plotter.open_gif(gif_filename)
        # Orbit and create frames
        for i in range(36):
            plotter.camera.azimuth += 10
            plotter.write_frame()
        plotter.close() # Finalizes the GIF

        print(f"‚úÖ Saved GIF preview: {gif_filename}")

        jobs[job_id]["status"] = "completed"
        jobs[job_id]["result"] = {
            "glb_url": f"/assets/{job_id}.glb", "gif_url": f"/assets/{job_id}.gif", "ply_url": f"/assets/{job_id}.ply",
        }
        print(f"‚úÖ Job {job_id} completed successfully!")

    except Exception as e:
        traceback.print_exc()
        print(f"‚ùå Error in job {job_id}: {e}")
        jobs[job_id]["status"] = "failed"
        jobs[job_id]["error"] = str(e)

p = FastAPI(title="3D Asset Prototyper API")
app.mount("/assets", StaticFiles(directory="generated_assets"), name="assets")

@app.get("/", summary="Root Endpoint")
async def root():
    return {"message": "Welcome to the 3D Model Generation API!", "documentation": "/docs", "status_endpoint": "/status"}

@app.get("/status", summary="Get Model and Server Status")
async def model_status():
    return {"status": "online", "model_version": MODEL_VERSION, "uptime_seconds": round(time.time() - UPTIME, 2), "device": str(device)}

@app.post("/generate3d", status_code=202, summary="Start a 3D Model Generation Job")
async def generate_3d_endpoint(prompt: str, background_tasks: BackgroundTasks):
    if not prompt: raise fastapi.HTTPException(status_code=400, detail="Prompt cannot be empty.")
    job_id = str(uuid.uuid4())
    jobs[job_id] = {"id": job_id, "prompt": prompt, "status": "queued", "start_time": time.time()}
    background_tasks.add_task(generate_3d_asset, job_id, prompt)
    return {"message": "3D model generation job has been queued.", "job_id": job_id, "status_url": f"/job/{job_id}"}

@app.get("/job/{job_id}", summary="Check Job Status")
async def get_job_status(job_id: str):
    job = jobs.get(job_id)
    if not job: raise fastapi.HTTPException(status_code=404, detail="Job not found")
    response = job.copy()
    if "start_time" in response: response["elapsed_time_seconds"] = round(time.time() - response["start_time"], 2)
    return response

@app.get("/assets/{file_name}", summary="Serve a Generated Asset")
async def get_asset(file_name: str):
    file_path = os.path.join("generated_assets", file_name)
    if not os.path.exists(file_path): raise fastapi.HTTPException(status_code=404, detail="File not found")
    return FileResponse(file_path)

NGROK_AUTH_TOKEN = "2zb3LukOW9Cj13UCr6GNJb19RVI_6a1rhyjTnW9gFS6mQjZae" # PASTE YOUR NGROK TOKEN HERE

if NGROK_AUTH_TOKEN == "YOUR_NGROK_AUTHTOKEN_HERE":
    print("‚ùå Please paste your ngrok authtoken into the NGROK_AUTH_TOKEN variable!")
else:
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
    nest_asyncio.apply()
    public_url = ngrok.connect(8000)
    print(f"üöÄ Public API URL: {public_url}")
    print(f"üìö API Docs available at: {public_url}/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)